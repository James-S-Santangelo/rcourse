---
title: "Randomization tests"
author: "James S. Santangelo"
output: pdf_document
---

## Lesson preamble

> ### Learning objectives
>
> - Learn to simulate small-scale data in R. 
> - Understand the basic logic underlying randomization tests and how they differ from standard parametric statistic tests. 
> - Apply randomization test to real ecological community data.

> 
> ### Lesson outline
> 
> Total lesson time: 2 hours
>
> - Brief intro to randomization tests (10 min)
> - Simulating small-scale data in R (30 mins)
> - General procedure for conducting a randomization test (10 mins)
> - Simulate data and perform t-test (10 mins)
> - Perform randomization test on same simulated data (30 mins)
> - Perform randomization test on real ecological data (30 mins)
> 
> ### Setup
>
> - `install.packages('dplyr')` (or `tidyverse`)
> - `install.packages('ggplot2')` (or `tidyverse`)

## Introduction to randomization tests

As we saw in previous weeks, standard parametric statistical tests (e.g. ANOVA, standard linear regression) have numerous assumptions that should be respected prior to drawing conclusions from their results. Violation of these assumtions can lead to erroneous conclusions about the population(s) you are trying to understand. Mixed-effects models provided us with a few ways of overcoming the limitations of standard models, while still using all of our data and remaining in a statistical framework that we generally understand and are comfortable with. Randomization tests provide yet another alternative solution to paramateric tests, although it's import that we understand how they differ.

Many ecological and evolutionary hypotheses ask: **Is the observed pattern different than what we would expect by random chance?** In other words, the null hypothesis is randomness. Randomization tests (sometimes called permutation tests) allow us to test whether the observed data is different than randomness distribution generated by reordering our observed data. If the pattern is random, then it should be just as likely as any other pattern generated by reordering the data. If it is not random, then it should occur more or less frequently than we expect under this distribution.

Randomization tests do not require that we make the same assumptions about our data as standard parametric tests. We do not require that samples be randomly drawn from the population since the goal of randomization tests is not to estimate parameters about the population (parameter estimation requires random samples to estimate means and variances). Similarly, we do not require normality of the data nor do we need equal variances among treatment groups since we are not really thinking about the population from which the data came and are not testing against a distribution (e.g. _t_ distribution) with known shape. This will all become more clear when we walk through an example. But first, an aside.

## An aside on simulating data in R

R allows us to genetate fake data (i.e. simulate data) rather easily. This is useful if we just want some toy data to play around with, want to simulate data simular to the type we will collect in an experiment to test our analyses, or want to simulate data collection many times to estimate population parameters (e.g. variance or standard deviation). We can sample existing (i.e. real) data using the `sample()` function, or take random samples from known statistical distributions (e.g. Normal distribtuion). We will return to `sample()` later in this lesson. For now, let's focus on sampling from known distributions. 

We'll start by taking random samples from a normal distribution with mean equal to 1 and standard deviation equal to 0. 

```{r}
# Load in ggplot2
library(ggplot2)

set.seed(42) # Ensure reproducibility of random results.
mean <- 0
sd <- 1
n <- 100
x <- rnorm(n, mean, sd)

# Fancy plot, if desired
ggplot(data.frame(x), aes(x=x)) +
    geom_histogram(color="black", fill="white") +
    annotate("text", x = -0.25, y = 9, label = round(mean(x), 4)) +
    annotate("text", x = -0.25, y = 9.5, label = "Mean") +
    ylab("Count") +
    geom_vline(xintercept = mean(x), linetype = "dashed", size = 1, colour = "red") +
    theme_classic()

# Get mean
mean(x)
```

Note how the mean from the above distribution (0.0325) is not exactly the same as the mean we specified (0). This should not be too surprising since we took *random* samples from a normal distribution and there is likely going to be variance within these samples. However, if we were to repeat this sampling many times (e.g. 10,000), each time plotting the mean of the distribution, we would expect the mean of this new distribution (i.e. the mean of the 10,000 means) to be much closer to what we specified. Let's try this. 

```{r}
set.seed(43)
mean <- 0
sd <- 1
size <- 100
x <- replicate(10000, mean(rnorm(size, mean, sd)))

# Fancy plot, if desired
ggplot(data.frame(x), aes(x=x)) +
    geom_histogram(color="black", fill="white") +
    annotate("text", x = -0.055, y = 1050, label = round(mean(x), 4)) +
    annotate("text", x = -0.055, y = 1100, label = "Mean") +
    ylab("Count") +
    geom_vline(xintercept = mean(x), linetype = "dashed", size = 1, colour = "red") +
    theme_classic()

# Get mean
mean(x)
```

As expected, the above distribution is normal and it's mean is much closer to 0 than the distribution generated by sampling only a single time. Interestingly, the same would be true even if the samples that we were originally drawing did not come from a normal distribution. For those who took introductory stats, you might remember that this is called the Central Limit Theorem, which states that the distribution of sample means approaches a normal distribution regardless of the shape of the original population's distribution. 

**Challenge: Demonstrate CLT with exponential data**

Note that we could also simulate data from a linear model (or any other model), as the example below shows.

```{r}
set.seed(44)

y_intercept <- 5.1
beta <- 0.23
x <- rnorm(25, mean = 7.6, sd = 0.7)
error <- rnorm(x, mean = 0, sd = 0.5)

y <- y_intercept + beta*x + error

model <- lm(y ~ x)
summary(model)
plot(y ~ x)
abline(model)
```

## Walkthrough of randomization test

Now that we knwo how to simulate data, let's use this to demonstrate the logic underlying randomization tests. The basic procedure for a randomization test is as follows:

1. Calculate test statistic for the sample data (e.g. difference in means, difference in means, t-statistic, etc.). The test statistic is chosen by the researcher.
2. Randomly reshuffle observations among the treatment groups, each time calculating a test statistic. 
3. Repeat 2 multiple times, generating a distribution of test-statistics.
4. Calculate the proportion of times the actual test statistic is outside the distribution of test-statistics.

We will perform the above approach on some simulated data. Imagine we had ventured to South America and collected 10 male and 10 female Hercules beetles. We brought the beetles back to the lab and measure the width of their bodies at the largest point. The main question we are interested in is: **Do male and female Hercules beetles differ in body width?** We will assume that body width is normally distributed. 

```{r}
set.seed(46)

# Male data
df_males <- data.frame(
    width = rnorm(10, mean=16.5, sd=2.5),
    sex = "Male"
)

# Female data
df_females <- data.frame(
    width = rnorm(n=10, mean=15, sd=1.8),
    sex = "Female"
)

# Let's look at the male and female data
ggplot() +
    ylab("Count") + xlab("Body width") +
    geom_histogram(data = df_males, aes(x = width), bins = 30, fill = "red", alpha = 0.4, colour = "black") +
    geom_histogram(data = df_females, aes(x = width), bins = 30, fill = "blue", alpha = 0.4, colour = "black") +
    geom_vline(data = df_males, aes(xintercept = mean(width)), size = 1, linetype = "dashed", colour = "red") +
    geom_vline(data = df_females, aes(xintercept = mean(width)), size = 1, linetype = "dashed", colour = "blue") +
    theme_classic() 

# Means for males and females
cat("Males have a mean body width of", mean(df_males$width), "\n")
cat("Females have a mean body width of", mean(df_females$width))
```

We will use a randomization test to test if males and females differ in body width. If they do **not** differ, then each body width measurement in our dataframe should be equally likely to belong to a male or to a female. In other words, body width should independent of beetle sex. We can simulate this by randomly rearranging the body width values, effectively removing the effect of sex on body width, and then calculating a test statistic (e.g. _t_ statistic, difference in means). We can do this many times (e.g. 10,000) and ask how many times our observed test statistic falls outside the randomly generated distribution of test statistics. We will use the difference in mean body width as our test statistic so let's go ahead and calculate the observed difference in body width between male and female beetles.

```{r}
mean_males <- mean(df_males$width)
mean_females <- mean(df_females$width)

diff_means_obs <- mean_males - mean_females
cat("The observed difference in mean body width between male and female Hercules beetles is", diff_means_obs)
```

Traditionally, if we wanted to determine if there is a significant difference in means between two groups, we would use a **t-test**. Let's perform a t-test on these data so we could compare it to the results of the randomization test that we will perform. Note the `alternative = two.sided` argument passed to `t.test()`. Since we are interested in whether males and females differ in mean body length without reference to whether one sex is _specifically_ larger or smaller than the other, we are performing a two-sided hypothesis test. Realistically, males could either have larger or smaller body widths so two-tailed test is appropriate here.

```{r}
t.test(df_males$width, df_females$width, alternative = "two.sided")
```

From the t-test above, we see that our t-statistic has a value of 2.49 and that males and females differ significantly in body width (_P_ < 0.05). From the means reported in the t-test, it looks like males have larger body widths than females (17.36 vs. 15.03). Let's now perform a randomization test. To get a better sense of what we're doing, let's first perform a single reshuffling of the data and look at the resulting distribution of the data. 

```{r message=FALSE, warning=FALSE}
# Load in dplyr
library(dplyr)

# Set seed for reproducible results
set.seed(47)

# Let's combine the male and female dataframes together
data_combined <- full_join(df_males, df_females)

# Randomly reshuffle the width column
reshuffled <- data_combined
reshuffled$width <- sample(reshuffled$width, size = nrow(reshuffled), replace = FALSE)

# View data to confirm that values have been reshuffle
head(data_combined)
head(reshuffled)
```

Note the differences in body width values between the original and reshuffled dataframes above.

```{r}
# Plot histograms of reshuffled data
ggplot(reshuffled, aes(x = width)) +
    ylab("Count") + xlab("Body width") +
    geom_histogram(data = reshuffled[reshuffled$sex == "Male",], aes(x = width), bins = 30, fill = "red", alpha = 0.4, colour = "black") +
    geom_histogram(data = reshuffled[reshuffled$sex == "Female",], aes(x = width), bins = 30, fill = "blue", alpha = 0.4, colour = "black") +
    geom_vline(data = reshuffled[reshuffled$sex == "Male",], aes(xintercept = mean(width)), size = 1, linetype = "dashed", colour = "red") +
    geom_vline(data = reshuffled[reshuffled$sex == "Female",], aes(xintercept = mean(width)), size = 1, linetype = "dashed", colour = "blue") +
    theme_classic()

# Let get the mean difference of this single simulation
means_sim1 <- group_by(reshuffled, sex) %>% summarize(mean = mean(width))
mean_diff_sim1 <- means_sim1[means_sim1$sex == "Male", "mean"] - means_sim1[means_sim1$sex == "Female", "mean"]
cat("The mean difference from a single reshuffling of the data is", mean_diff_sim1$mean)
```

We can see that the mean difference from the simulated data is considerably different from the observed mean difference. This makes sense since the body width values were randomly assigned to males and females. Let's now do this 5,000 times, each time calculating the mean difference in body width.

```{r message=FALSE, warning=FALSE}
# Set seed for reproducible results
set.seed(49)

# Initialize a list to store the simulated test-statistics
simulated_means <- list()

nreps = 5000 # 5000 iterations

for(i in 1:nreps){
    
    # Create temporary dataframe to permute so we don't modify the original
    reshuffled <- data_combined 
    
    # Permute the width column with the 'sample()' function. 
    reshuffled$width <- sample(reshuffled$width, size = nrow(reshuffled), replace = FALSE)
    
    # Use dplyr to calculate the means for each sex
    means <- group_by(reshuffled, sex) %>% summarize(mean = mean(width))
    
    # Calculate to difference between simulated male and female body width means
    mean_calc <- means[means$sex == "Male", "mean"] - means[means$sex == "Female", "mean"]
    
    # Append simulated mean difference to list
    simulated_means[i] <- mean_calc
}    

# Unlist simulated means list into numeric vector
simulated_means <- unlist(simulated_means)

# Show first 10 simulated mean differences
simulated_means[1:10]
```

We now have a numeric vector containing 1,000 simulated differences in mean body width between males and females. Let's plot a histogram of the simulated values and overlay onto the histogram our observe mean difference. 

```{r}
ggplot() +
    ylab("Count") + xlab("Simulated mean difference") +
    geom_histogram(aes(x = simulated_means), bins = 30, fill = "grey", alpha = 0.4, colour = "black") +
    geom_vline(xintercept = diff_means_obs, size = 1, linetype = "dashed", colour = "black") + 
    theme_classic()

```

Finally, to get out P-value, we calculate the number of times our observed value the simulated mean difference exeede the observed mean difference from our data. Because we are performing a two-tailed test, this amounts to determining the number of times the simulated mean difference is **either greater or lesser than the observed difference**. We can do this by asking how many times the absolute value of the simulated mean difference is greater or equal to the absolute value of the observed mean difference.

```{r}
abs_simulated_means <- abs(simulated_means)
abs_diff_means_obs <- abs(diff_means_obs)
exceed_count <- length(abs_simulated_means[abs_simulated_means >= abs_diff_means_obs])
p_val <- exceed_count / nreps
cat("The P-value from the randomization test is", p_val)
```

As we can see, the randomization test provides results that are largely consistent with the t-test. This is not surprizing since we specifically sampled independent data from normal distributions with similar variances. In other words, our sampled data do not violate any of the assumptions of the t-test and in such a case the difference in means is by definition analogous to the _t_ statistic used in the t-test. There are some cases where randomization tests provide more accurate (or _exact_) P-values than parametric tests (e.g. small samples from skewed distributions) but even more diverse applications of randomization tests are found in ecology and evolutionary biology.

## Randomization tests: A real-world application

