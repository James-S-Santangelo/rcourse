---
title: "Manipulating and analyzing data with dplyr"
---


**Copyright (c) Data Carpentry**

*Note: This lecture content was originally created by voluntary contributions to
[Data Carpentry](http://datacarpentry.org) and has been modified to
align with the aims of EEB430. Data Carpentry is an organization focused on data
literacy, with the objective of teaching skills to researchers to enable them to
retrieve, view, manipulate, analyze, and store their and otherâ€™s data in an open
and reproducible way in order to extract knowledge from data. For EEB430, we are
making all our content available under the same license, [The Creative Commons](https://creativecommons.org/), 
license, so if that anyone in the future can re-use or modify our course content, without infringing on copyright licensing issues.*


> ## Learning objectives
>
> * Describe what a data frame is.
> * Load external data from a .csv file into a data frame in R.
> * Summarize the contents of a data frame in R.
> * Understand the purpose of the **`dplyr`** package.
> * Learn to use data wrangling commands `select`, `filter`, `%>%,` and `mutate`
> from the **`dplyr`** package.
> * Understand the split-apply-combine concept for data analysis.
> * Use `summarize`, `group_by`, and `tally` to split a data frame into groups
> of observations, apply a summary statistics for each group, and then combine
> the results.


## Lesson outline

- Data set background (10 min)
- What are data frames (15 min)
- R packages for data analyses (5 min)
- Data wrangling in dplyr (40 min)


## Dataset background

Today, we will be working with real data from a longitudinal study of the
species abundance in the Chihuahuan desert ecosystem near Portal, Arizona, USA.
This study includes observations of plants, ants and rodents from 1977 - 2002,
and has been used in over 100 publications. More information is available in
[the abstract of this paper from 2009](
http://onlinelibrary.wiley.com/doi/10.1890/08-1222.1/full). There are several
data sets available related to this study, and we will be working with data sets that
have been preprocessed by the data carpentry organization to facilitate
teaching. These are made available online as _The Portal project teaching
database_, both at the [data carpentry
website](http://www.datacarpentry.org/ecology-workshop/data/), and on
[Figshare](https://figshare.com/articles/Portal_Project_Teaching_Database/1314459/6),
which is a great place to publish data and figures openly to make them available
for other researchers and to communicate findings that are not part of a longer
paper.


## Presentation of the Survey Data

We are studying the species and weight of animals caught in plots in our study
area. The dataset is stored as a comma separated value (CSV) file. Each row
holds information for a single animal, and the columns represent:

| Column           | Description                        |
|------------------|------------------------------------|
| record_id       | Unique id for the observation      |
| month            | month of observation               |
| day              | day of observation                 |
| year             | year of observation                |
| plot_id         | ID of a particular plot            |
| species_id      | 2-letter code                      |
| sex              | sex of animal ("M", "F")           |
| hindfoot_length | length of the hindfoot in mm       |
| weight           | weight of the animal in grams      |
| genus            | genus of animal                    |
| species          | species of animal                  |
| taxa             | e.g. Rodent, Reptile, Bird, Rabbit |
| plot_type       | type of plot                       |

To read the data into R, we are going to use a function called `read_csv`. This
function is contained in an R-package called `readr`. R-packages are a bit like
browser extensions, they are not essential, but can provide nifty functionality.
We will go through R-packages in general and which ones are good for data
analyses in particular in detail later in this lecture. Now, let's install
`readr`:

```{r, eval=FALSE}
install.packages('readr') # You only need to install a package once
```

Now we can use the `read_csv` function. One useful thing that `read_csv`
enables, is the ability to read a CSV file directly from a URL, without
downloading it in a separate step:

```{r, eval=FALSE}
surveys <- readr::read_csv('https://ndownloader.figshare.com/files/2292169')
```

However, it is often a good idea to download the data first, so you have a copy
stored locally on your computer in case you want to do some offline analyses or
the file online changes or is taken down. You can either download the data
manually or form within R:

```{r, eval=FALSE}
download.file("https://ndownloader.figshare.com/files/2292169",
              "portal_data.csv") # Saves this name in the current directory
```

The data is read in by specifying its local path.

```{r}
surveys <- readr::read_csv('portal_data.csv')
```

This statement produces some output regarding which data type it found in each 
column. If we want to check this in more detail, we can print the variable's 
value: `surveys`.

```{r}
surveys
```

You can see that the R Notebook provides us with this nice tabular display
format of the data, which also includes pagination when there are many rows and
we can click this arrow to view all the columns. Technically, this is actually a
`tibble` rather than a data frame as indicated in the output. This is because we
used `read_csv` to load it. Since a `tibble` is just a data frame with some
convenient extra functionality, we will use these words interchangeably from now
on.

If we just want to glance at how the data frame looks, it is sufficient to display only the
top (the first 6 lines) using the function `head()`:

```{r}
head(surveys)
```

## What are data frames?

Data frames are the _de facto_ data structure for most tabular data, and what we
use for statistics and plotting.

A data frame can be created by hand, but most commonly they are generated by the
function `read_csv()`in other words, when importing spreadsheets from your hard
drive (or the web).

A data frame is the representation of data in the format of a table where the
columns are vectors that all have the same length. Because the column are
vectors, they all contain the same type of data as we discussed in last class
(e.g., characters, integers, factors). For example, here is a figure depicting a
data frame comprising of a numeric, a character and a logical vector.

We can see this when inspecting the **str**ucture of a data frame with the
function `str()`:

```{r}
str(surveys)
```

Integer refers to a whole number, such as 1, 2, 3, 4, etc. Numbers with
decimals, 1.0, 2.4, 3.333, are referred to as floats. Factors are used to
represent categorical data. Factors can be ordered or unordered, and
understanding them is necessary for statistical analysis and for plotting.
Factors are stored as integers, and have labels (text) associated with these
unique integers. While factors look (and often behave) like character vectors,
they are actually integers under the hood, and you need to be careful when
treating them like strings.


## Inspecting `data.frame` Objects

We already saw how the functions `head()` and `str()` can be useful to check the
content and the structure of a data frame. Here is a non-exhaustive list of
functions to get a sense of the content/structure of the data. Let's try them
out!

* Size:
    * `dim(surveys)` - returns a vector with the number of rows in the first element,
          and the number of columns as the second element (the **dim**ensions of
          the object)
    * `nrow(surveys)` - returns the number of rows
    * `ncol(surveys)` - returns the number of columns

* Content:
    * `head(surveys)` - shows the first 6 rows
    * `tail(surveys)` - shows the last 6 rows

* Names:
    * `names(surveys)` - returns the column names (synonym of `colnames()` for `data.frame`
	   objects)
    * `rownames(surveys)` - returns the row names

* Summary:
    * `str(surveys)` - structure of the object and information about the class, length and
	   content of  each column
    * `summary(surveys)` - summary statistics for each column

Note: most of these functions are "generic", they can be used on other types of
objects besides `data.frame`.

> ### Challenge
>
> Based on the output of `str(surveys)`, can you answer the following questions?
>
> * What is the class of the object `surveys`?
> * How many rows and how many columns are in this object?
> * How many species have been recorded during these surveys?

<!---
```{r, echo=FALSE}
## Answers
##
## * class: data frame
## * how many rows: 34786,  how many columns: 13
## * how many species: 48
```
--->


## Indexing and subsetting data frames

Our survey data frame has rows and columns (it has 2 dimensions), if we want to
extract some specific data from it, we need to specify the "coordinates" we want
from it. Row numbers come first, followed by column numbers. However, note that
different ways of specifying these coordinates lead to results with different
classes.

```{r}
surveys[1, 1]   # first element in the first column of the data frame (as a vector)
surveys[1, 6]   # first element in the 6th column (as a vector)
surveys[, 1]    # first column in the data frame (as a vector)
surveys[1]      # first column in the data frame (as a data.frame)
surveys[1:3, 7] # first three elements in the 7th column (as a vector)
surveys[3, ]    # the 3rd element for all columns (as a data.frame)
head_surveys <- surveys[1:6, ] # equivalent to head(surveys)
```

`:` is a special function that creates numeric vectors of integers in increasing
or decreasing order, test `1:10` and `10:1` for instance. This works similar to
`seq`, which we looked at earlier in class:

```{r}
0:10
seq(0, 10)

# We can test if all elements are the same
0:10 == seq(0,10)
all(0:10 == seq(0,10))
```

You can also exclude certain parts of a data frame using the "`-`" sign:

```{r}
surveys[,-1]    # All columns, except the first
surveys[-c(7:34786),] # Equivalent to head(surveys)
```

As well as using numeric values to subset a `data.frame` (or `matrix`), columns
can be called by name, using one of the four following notations: <!-- Note sure how important it is to learn these difference vs just teaching the preferred way with the footnote that there are other ways also. -->

```{r}
head(surveys["species_id"])       # Result is a data.frame
head(surveys[, "species_id"])     # Result is a vector
head(surveys[["species_id"]])     # Result is a vector
head(surveys$species_id)          # Result is a vector
```

For our purposes, the last three notations are equivalent. RStudio knows about
the columns in your data frame, so you can take advantage of the autocompletion
feature to get the full and correct column name.

> ### Challenge
>
> 1. Create a `data.frame` (`surveys_200`) containing only the observations from
>    row 200 of the `surveys` dataset.
>
> 2. Notice how `nrow()` gave you the number of rows in a `data.frame`?
>
>      * Use that number to pull out just that last row in the data frame.
>      * Compare that with what you see as the last row using `tail()` to make
>        sure it's meeting expectations.
>      * Pull out that last row using `nrow()` instead of the row number.
>      * Create a new data frame object (`surveys_last`) from that last row.
>
> 3. Use `nrow()` to extract the row that is in the middle of the data
>    frame. Store the content of this row in an object named `surveys_middle`.
>
> 4. Combine `nrow()` with the `-` notation above to reproduce the behavior of
>    `head(surveys)` keeping just the first through 6th rows of the surveys
>    dataset.

<!---
```{r}
## Answers
surveys_200 <- surveys[200, ]
surveys_last <- surveys[nrow(surveys), ]
surveys_middle <- surveys[nrow(surveys)/2, ]
surveys_head <- surveys[-c(7:nrow(surveys)),]
```
--->


## Exploratory data analyses (EDA) in R

There are certainly many tools built-in to base R which can be used to
understand data, but we are going to use a package called `dplyr` which makes
exploratory data analysis particularly intuitive and effective.


### R packages

First, let's explain the concept of an R-package. What we have used so far, is
all part of base R (except `read_csv`), together with many more functions. Every
package included in base R, will be installed on any computer where R is
installed, since they are considered critical for using R, e.g. `c()`, `mean()`,
`+`, `-`, etc. However, since R is an open language, it is easy to develop your
own R-packages that provides new functionality and submit it to the official
repository for R-packages called CRAN (Comprehensive R Archive Network). CRAN
has thousands of packages, and all these cannot be installed by default, because
then base R installation would be huge and most people would only be using a
fraction of everything installed on their machine. It would be like if you
downloaded the Firefox or Chrome browser and you would get all extensions and
addons installed by default, or as if your phone came with every app ever made
for it already installed when you bought it, quite impractical.

To install a package in R, we use the function `install.packages()`. In this
case, the package `dplyr` is part of a bigger collections of packages called
[`tidyverse`](https://www.tidyverse.org/) (just like Microsoft Word is part of
Microsoft Office), which also contains the `readr` package we installed in the
beginning and many more packages that makes exploratory data analyses more
intuitive and effective. 

```{r, eval=FALSE}
install.packages('tidyverse')
```

Now all the `dplyr` functions are available to us by prefacing them with
`dplyr::`:

```{r}
dplyr::glimpse(surveys) # `glimpse` is similar to `str` 
```

We will be using this package a lot, and it would be a little annoying to have
to type `dplyr::` every time, so we will load it into our current environment.
This needs to be done once for every new R sessions and makes all functions
accessible without the their package prefix, which is very convenient, as long
as you are aware of which function you are using and don't load a function with
the same name from two different packages.

```{r}
# We could also do library(dplyr), but we need the rest of the
# tidyverse packages later, so we might as well import the entire collection.
library('tidyverse')
glimpse(surveys)
```


### Data wrangling with dplyr

Wrangling here is used in the sense of maneuvering, managing, controlling, and
turning your data upside down and inside out to look at it from different angles
in order to understand it. The package **`dplyr`** provides easy tools for the
most common data manipulation tasks. It is built to work directly with data
frames, with many common tasks optimized by being written in a compiled language
(C++), this means that many operations runs much faster than for similar tools
in R. An additional feature is the ability to work directly with data stored in
an external database, such as SQL-databases. The ability to work with databases
is great because you are allowed to work with much bigger datasets (100s of GB)
than your computer could normally handle. We will not talk in detail about this
in class, but there are great resources online to learn more (e.g. [this lecture
from data
carpentry](http://www.datacarpentry.org/R-ecology-lesson/05-r-and-databases.html)).


### Selecting columns and filtering rows

We're going to learn some of the most common **`dplyr`** functions: `select()`,
`filter()`, `mutate()`, `group_by()`, and `summarize()`. To select columns of a
data frame, use `select()`. The first argument to this function is the data
frame (`surveys`), and the subsequent arguments are the columns to keep.

```{r}
select(surveys, plot_id, species_id, weight, year)
```

To choose rows based on a specific criteria, use `filter()`:

```{r}
filter(surveys, year == 1995)
```


### Pipes

But what if you wanted to select and filter at the same time? There are three
ways to do this: use intermediate steps, nested functions, or pipes. With
intermediate steps, you essentially create a temporary data frame and use that
as input to the next function. This can clutter up your workspace with lots of
objects:

```{r}
temp_df <- select(surveys, plot_id, species_id, weight, year)
filter(temp_df, year == 1995)
```

You can also nest functions (i.e. one function inside of another).
This is handy, but can be difficult to read if too many functions are nested as
things are evaluated from the inside out.

```{r}
filter(select(surveys, plot_id, species_id, weight, year), year == 1995)
```

The last option, pipes, are a fairly recent addition to R. Pipes let you take
the output of one function and send it directly to the next, which is useful
when you need to do many things to the same dataset.  Pipes in R look like `%>%`
and are made available via the `magrittr` package that also is included in the
`tidyverse`. If you use RStudio, you can type the pipe with <kbd>Ctrl</kbd> +
<kbd>Shift</kbd> + <kbd>M</kbd> if you have a PC or <kbd>Cmd</kbd> +
<kbd>Shift</kbd> + <kbd>M</kbd> if you have a Mac.

```{r}
surveys %>% 
    select(plot_id, species_id, weight, year) %>% 
    filter(year == 1995)
```

Another example:

```{r}
surveys %>%
  filter(weight < 5) %>%
  select(species_id, sex, weight)
```

In the above, we use the pipe to send the `surveys` dataset first through
`filter()` to keep rows where `weight` is less than 5, then through `select()`
to keep only the `species_id`, `sex`, and `weight` columns. Since `%>%` takes
the object on its left and passes it as the first argument to the function on
its right, we don't need to explicitly include it as an argument to the
`filter()` and `select()` functions anymore.

If this runs off your screen and you just want to see the first few rows, you
can use a pipe to view the `head()` of the data. (Pipes work with
non-**`dplyr`** functions, too, as long as the **`dplyr`** or `magrittr` package
is loaded).

```{r}
surveys %>%
  filter(weight < 5) %>%
  select(species_id, sex, weight) %>% 
  head()
```

If we wanted to create a new object with this smaller version of the data, we
could do so by assigning it a new name:

```{r}
surveys_sml <- surveys %>%
  filter(weight < 5) %>%
  select(species_id, sex, weight)

surveys_sml
```

Note that the final data frame is the leftmost part of this expression.

A single expression can also be used to filter for several criteria, either
matching _all_ criteria (`&`) or _any_ criteria (`|`):

```{r}
surveys %>% 
    filter(taxa == 'Rodent' & sex == 'F') %>% 
    select(sex, taxa)
```

```{r, eval=FALSE}
surveys %>% 
    filter(species == 'clarki' | species == 'leucophrys') %>% 
    select(species, taxa)
```

> ### Challenge
>
>  Using pipes, subset the `survey` data to include individuals collected before
>  1995 and retain only the columns `year`, `sex`, and `weight`.

<!---
```{r, eval=FALSE}
## Answer
surveys %>%
    filter(year < 1995) %>%
    select(year, sex, weight)
```
--->


### Mutate

Frequently you'll want to create new columns based on the values in existing
columns, for example to do unit conversions, or find the ratio of values in two
columns. For this we'll use `mutate()`.

To create a new column of weight in kg:

```{r}
surveys %>%
    mutate(weight_kg = weight / 1000)
```

You can also create a second new column based on the first new column within the
same call of `mutate()`:

```{r}
surveys %>%
    mutate(weight_kg = weight / 1000,
           weight_kg2 = weight_kg * 2)
```

The first few rows of the output are full of `NA`s, so if we wanted to remove
those we could insert a `filter()` in the chain:

```{r}
surveys %>%
    filter(!is.na(weight)) %>%
    mutate(weight_kg = weight / 1000)
```

`is.na()` is a function that determines whether something is an `NA`. The `!`
symbol negates the result, so we're asking for everything that *is not* an `NA`.

> ### Challenge
>
>  Create a new data frame from the `surveys` data that meets the following
>  criteria: contains only the `species_id` column and a new column called
>  `hindfoot_half` containing values that are half the `hindfoot_length` values.
>  In this `hindfoot_half` column, there are no `NA`s and all values are less
>  than 30.
>
>  **Hint**: think about how the commands should be ordered to produce this data frame!

<!---
```{r, eval=FALSE}
## Answer
surveys_hindfoot_half <- surveys %>%
    filter(!is.na(hindfoot_length)) %>%
    mutate(hindfoot_half = hindfoot_length / 2) %>%
    filter(hindfoot_half < 30) %>%
    select(species_id, hindfoot_half)
```
--->


### Split-apply-combine data analysis and the summarize() function

Many data analysis tasks can be approached using the *split-apply-combine*
paradigm: split the data into groups, apply some analysis to each group, and
then combine the results. **`dplyr`** makes this very easy through the use of
the `group_by()` function.


#### The `summarize()` function

`group_by()` is often used together with `summarize()`, which collapses each
group into a single-row summary of that group.  `group_by()` takes as arguments
the column names that contain the **categorical** variables for which you want
to calculate the summary statistics. So to view the mean `weight` by sex:

```{r}
surveys %>%
    group_by(sex) %>%
    summarize(mean_weight = mean(weight, na.rm = TRUE))
```

You can also group by multiple columns:

```{r}
surveys %>%
    group_by(sex, species_id) %>%
    summarize(mean_weight = mean(weight, na.rm = TRUE))
```

When grouping both by `sex` and `species_id`, the first rows are for individuals
that escaped before their sex could be determined and weighted. You may notice
that the last column does not contain `NA` but `NaN` (which refers to "Not a
Number", this is only visible in the interactive Notebook, not the knitted output). To avoid this, we can remove the missing values for weight before we
attempt to calculate the summary statistics on weight. Because the missing
values are removed, we can omit `na.rm = TRUE` when computing the mean:

```{r}
surveys %>%
    filter(!is.na(weight)) %>%
    group_by(sex, species_id) %>%
    summarize(mean_weight = mean(weight))
```

Note that the number of not displayed rows decreased from 82 to 54. If you want
to display more data, you can use the `print()` function at the end of your
chain with the argument `n` specifying the number of rows to display:

```{r}
surveys %>%
    filter(!is.na(weight)) %>%
    group_by(sex, species_id) %>%
    summarize(mean_weight = mean(weight)) %>%
    print(n = 15)
```

Once the data are grouped, you can also summarize multiple variables at the same
time (and not necessarily on the same variable). For instance, we could add a
column indicating the minimum weight for each species for each sex:

```{r}
surveys %>%
    filter(!is.na(weight)) %>%
    group_by(sex, species_id) %>%
    summarize(mean_weight = mean(weight),
              min_weight = min(weight))
```


#### Tallying

When working with data, it is also common to want to know the number of
observations found for each factor or combination of factors. For this, **`dplyr`**
provides `tally()`. For example, if we wanted to group by sex and find the
number of rows of data for each taxa, we would do:

```{r}
surveys %>%
    group_by(taxa) %>%
    tally()
```

We can also use `tally()` when grouping on multiple variables:

```{r}
surveys %>%
    group_by(taxa, sex) %>%
    tally()
```

Here, `tally()` is the action applied to the groups created by `group_by()` and
counts the total number of records for each category.

If there are many groups, `tally()` is not that useful on its own. For example,
when we want to view the five most abundant species among the observations:

```{r}
surveys %>% 
    group_by(species) %>% 
    tally()
```

Since there are 40 rows in this output, we would like to order the table to
display the most abundant species first. In `dplyr`, we say that we want to
`arrange()` the data.

```{r}
surveys %>% 
    group_by(species) %>% 
    tally() %>% 
    arrange(n)
```

Still not that useful. Since we are interested in the most abundant species, we
want to display those with the highest count first, in other words, we want to
arrange the column `n` in descending order:

```{r}
surveys %>% 
    group_by(species) %>% 
    tally() %>% 
    arrange(desc(n)) %>% 
    head(5)
```

If we want to include more attributes about these species, we can include these
in the call to `group_by()`:

```{r}
surveys %>% 
    group_by(species, taxa, genus) %>% 
    tally() %>% 
    arrange(desc(n)) %>% 
    head(5)
```

Be careful not to include anything that would split the group into subgroups,
such as `sex`, `year` etc.
 
> ### Challenge
>
> 1. How many individuals were caught in each `plot_type` surveyed?
>
> 2. Use `group_by()` and `summarize()` to find the mean, min, and max hindfoot
> length for each species (using `species_id`).
>
> 3. What was the heaviest animal measured in each year? Return the columns `year`,
> `genus`, `species_id`, and `weight`.
>
> 4. You saw above how to count the number of individuals of each `sex` using a
> combination of `group_by()` and `tally()`. How could you get the same result
> using `group_by()` and `summarize()`? Hint: see `?n`.

<!---
```{r, echo=FALSE}
## Answer 1
surveys %>%
    group_by(plot_type) %>%
    tally

## Answer 2
surveys %>%
    filter(!is.na(hindfoot_length)) %>%
    group_by(species_id) %>%
    summarize(
        mean_hindfoot_length = mean(hindfoot_length),
        min_hindfoot_length = min(hindfoot_length),
        max_hindfoot_length = max(hindfoot_length)
    )

## Answer 3
surveys %>%
    filter(!is.na(weight)) %>%
    group_by(year) %>%
    filter(weight == max(weight)) %>%
    select(year, genus, species, weight) %>%
    arrange(year)

## Answer 4
surveys %>%
  group_by(sex) %>%
  summarize(n = n())
```
--->

*Knit the notebook and save the resulting `.html` and the source `.Rmd` files to a USB stick or send them to yourself via email.*